{"cells":[{"cell_type":"markdown","metadata":{"id":"4c70109c"},"source":["# Exercise: Setting Up and Running a Llama-Cpp Model As a Chat\n","\n","This notebook demonstrates how to install dependencies, download a model from Hugging Face,\n","and load it using the `llama_cpp` library. Follow the steps below to understand how to:\n","- Install necessary Python packages.\n","- Download a GGUF model file from Hugging Face.\n","- Load and interact with the model as a chat.\n","\n","Make sure you have the required dependencies installed before running the notebook."]},{"cell_type":"code","source":["# Check GPU availability\n","!nvidia-smi"],"metadata":{"id":"tkyv8wXAvc3C"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eggKm2rsYYJk"},"outputs":[],"source":["# Install necessary dependencies for running the Llama model\n","!pip3 install llama-cpp-python==0.3.4 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124\n","!pip3 install huggingface_hub==0.28.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YLXagtryYd6g"},"outputs":[],"source":["# Import required libraries for model execution and downloading\n","from llama_cpp import Llama\n","from huggingface_hub import hf_hub_download"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MBKorQ47Yi3Q"},"outputs":[],"source":["# Download the LLM model file from Hugging Face\n","# Ensure the repository ID and filename match the desired model\n","# Download the LLM, you can search in Hugging Face for mode GGUF LLMs\n","model_path = hf_hub_download(\n","    repo_id=\"Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF\",\n","    filename=\"qwen2.5-coder-0.5b-instruct-q4_k_m.gguf\",\n","    force_download=False,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84vQDd8FYjco"},"outputs":[],"source":["# Create the LLM\n","llm = Llama(\n","    model_path=model_path,\n","    # n_gpu_layers=-1, # Uncomment to use GPU acceleration\n","    n_ctx=2048,  # Uncomment to increase the context window\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pOSAqSCdzD8"},"outputs":[],"source":["# Now prompt the LLM using a chat\n","llm.create_chat_completion(\n","      messages = [\n","          {\n","              \"role\": \"system\",\n","              \"content\": \"You are an assistant who perfectly describes images.\"\n","          },\n","          {\n","              \"role\": \"user\",\n","              \"content\": \"Name the planets in the solar system.\"\n","          }\n","      ]\n",")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}