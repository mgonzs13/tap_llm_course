{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install llama-cpp-python==0.2.82 huggingface_hub==0.23.4 langchain==0.1.16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ThfMovX_Mxt"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import LlamaGrammar\n",
        "from langchain.llms.llamacpp import LlamaCpp\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.vectorstores.chroma import Chroma\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz5e-KES_Mxu"
      },
      "outputs": [],
      "source": [
        "# download the model from HF\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"cstr/Spaetzle-v60-7b-GGUF\",\n",
        "    filename=\"Spaetzle-v60-7b-q4-k-m.gguf\",\n",
        "    force_download=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7u7itF8cS-P"
      },
      "outputs": [],
      "source": [
        "# create the grammar\n",
        "grammar_string = r\"\"\"\n",
        "root ::= command\n",
        "\n",
        "command ::= single-command | composed-command\n",
        "composed-command ::= single-command \"#\" command\n",
        "single-command ::= action \"(\" arguments \")\"\n",
        "\n",
        "action ::= \"MOTION\" | \"SEARCHING\" | \"TAKING\" | \"PLACING\" | \"BRINGING\"\n",
        "arguments ::= argument | argument \",\" arguments\n",
        "argument ::= argument-name \":\" string\n",
        "argument-name ::= \"theme\" | \"goal\" | \"source\" | \"path\" | \"ground\" | \"beneficiary\"\n",
        "\n",
        "string  ::=\n",
        "  \"\\\"\" (\n",
        "    [^\"\\\\\\x7F\\x00-\\x1F] |\n",
        "    \"\\\\\" ([\"\\\\/bfnrt] | \"u\" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F]) # escapes\n",
        "  )* \"\\\"\" ws\n",
        "ws  ::= ([ \\t\\n] ws)?\n",
        "\"\"\"\n",
        "\n",
        "grammar = LlamaGrammar.from_string(grammar_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O40apbZO_Mxu"
      },
      "outputs": [],
      "source": [
        "# create the LLM\n",
        "llm = LlamaCpp(\n",
        "    model_path=model_path,\n",
        "    stop=[\"### Instruction:\\n\"],\n",
        "    n_ctx=4096,\n",
        "    n_gpu_layers=33,\n",
        "    max_tokens=4096,\n",
        "    temperature=0.0,\n",
        "    streaming=False,\n",
        "    grammar=grammar\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR2WIUYp_Mxv"
      },
      "outputs": [],
      "source": [
        "# create the embeddings\n",
        "model_name = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "\n",
        "embeddings_model = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQnVIXyw_Mxv"
      },
      "outputs": [],
      "source": [
        "# create the vector db and the retriever\n",
        "db = Chroma(embedding_function=embeddings_model)\n",
        "\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "example_file = open(\"dataset/interpretations\", \"r\")\n",
        "examples = []\n",
        "\n",
        "for line in example_file:\n",
        "  examples.append(line.replace('\\t', ' = '))\n",
        "\n",
        "db.add_texts(examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvBdeJP4_Mxv"
      },
      "outputs": [],
      "source": [
        "# create the prompt\n",
        "template = (\n",
        "  \"You are an AI to convert text into CFR (Command Frame Representation).\"\n",
        "  \"Here you have some examples of converting text into CFR:\\n\"\n",
        "  \"{examples}\"\n",
        "\n",
        "  \"### Instruction:\\n\"\n",
        "  \"Convert the following text info CFR: {prompt}\\n\\n\"\n",
        "\n",
        "  \"### Response:\\n\"\n",
        ")\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvbQSG1m_Mxw"
      },
      "outputs": [],
      "source": [
        "# create the chain\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "\n",
        "def format_docs(docs):\n",
        "\n",
        "    text = \"\"\n",
        "\n",
        "    for d in docs:\n",
        "        text += f\"- {d.page_content.strip()}\\n\"\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "setup_and_retrieval = RunnableParallel(\n",
        "    {\"examples\": retriever | format_docs, \"prompt\": RunnablePassthrough()}\n",
        ")\n",
        "\n",
        "chain = setup_and_retrieval | prompt | llm | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA4lQa11_Mxw"
      },
      "outputs": [],
      "source": [
        "# prompt the LLM\n",
        "print(chain.invoke(\"go to the bedroom take all the clothes from the bed and put them in the table\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
